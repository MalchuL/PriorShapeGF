checkpoint_path: null

num_epochs: &num_epochs 1000
train_steps_limit: 1000
val_steps_limit: 1.0
val_batch_size: 20

lr: &lr 0.0002
weight_decay: &wd 0.0

points_count: &points_count 4096
valid_points_count: 15000
nearest_points_count: 15000
step_size_ratio: 1
num_steps: 1
weight: 1.0


log_freq: 10
log_point_cloud: 100
check_val_every_n_epoch: 30

trainer:
  sigma_begin: 0.1
  sigma_denominator: 10
  sigma_num: 10

  reconstruction_coef: 10

  sigma_momentum: 0.05
  update_sigmas_step: 100
  sigma_decrease_coef: 0.9

  folding_coef: 10
  folding_first_coef: 1

  folding_grid_coef: 2
  folding_grid_steps: 10000

  valid_chamfer_points: 2048

#  TODO если есть get_from_params тогда передаст в них, иначе вызовет как конструктор
encoder_params:
  model: PointNet2Featurizer
  out_features: &z_dim 512
  in_features: 0
  batchnorm: False


decoder_params:
  model: ShapeGFConditionalDecoder
  z_dim: *z_dim
  dim: 3
  out_dim: 3
  hidden_size: 256
  n_blocks: 16
  sigma_condition: True
  norm_method: group_norm

folding_decoder_params:
  model: FoldingNetDec3dSphere
  input_features: *z_dim
  samples: *points_count
  r: 1.0
  hidden_size: 1024
  #output_points: *points_count


data_params:
  num_workers: 8
  batch_size: 8

  train_dataset_path: /media/malchul/Новый том/Downloads_Ubuntu/ShapeNetCore.v2.PC15k/03001627
  val_dataset_path: /media/malchul/Новый том/Downloads_Ubuntu/ShapeNetCore.v2.PC15k/03001627


scheduler_params:
   scheduler: ExponentialLR
   gamma: 0.995405417351527



optimizer_params:
  optimizer: AdamW
  lr: *lr
  weight_decay: *wd


exp_name: &exp_name "ShapeGF_train"

hydra:
  run:
    dir: ./outputs/${now:%Y-%m-%d}/ShapeGF_${now:%H-%M-%S}_${exp_name}



